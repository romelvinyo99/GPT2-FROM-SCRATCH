{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c74602-d2a7-4623-a475-ece87e352d72",
   "metadata": {},
   "source": [
    "## ----------------------------Self-Attention Mechanism Trainable Weights--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62310c28-b4cc-49a9-8048-384d13e25e4d",
   "metadata": {},
   "source": [
    "## KEY NOTES\n",
    "\n",
    "- In this tutorial the weights are going to shift the inputs from the third dimension to the second dimension(R3 --> R2)\n",
    "- We are going to follow the rules of linear algebra --- kama hujui hii we iza tu but ni easy but its a good background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059348eb-cff6-4894-8645-0a96623caeb7",
   "metadata": {},
   "source": [
    "## Creating the input = token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d6cfe2d-e801-48ba-869b-9aee0afc139a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4300, 0.1500, 0.8900],\n",
       "        [0.5500, 0.8700, 0.6600],\n",
       "        [0.5700, 0.8500, 0.6400],\n",
       "        [0.2200, 0.5800, 0.3300],\n",
       "        [0.7700, 0.2500, 0.1000],\n",
       "        [0.0500, 0.8000, 0.5500]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the token embeddings - Randomized\n",
    "import torch\n",
    "output_dim = 3\n",
    "\n",
    "inputs = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # Your    # X1\n",
    "    [0.55, 0.87, 0.66], # journey # x2\n",
    "    [0.57, 0.85, 0.64], # begins  # X3\n",
    "    [0.22, 0.58, 0.33], # with    # X4\n",
    "    [0.77, 0.25, 0.10], # one     # X5\n",
    "    [0.05, 0.80, 0.55] # step     # X6\n",
    "])  \n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cee76d7-d832-4f36-b837-0801d573b51d",
   "metadata": {},
   "source": [
    "## Initialization the key, query and value weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3beaf914-e9eb-4f7c-bf9c-29951f9c730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs has shape = torch.Size([6, 3])\n",
      "The weights will have a shape of ([3, 2])\n",
      "The outputs key, value, query vectors shape will be ([6, 3])\n"
     ]
    }
   ],
   "source": [
    "# Lets check the shape of the inputs\n",
    "\n",
    "print(f\"The inputs has shape = {inputs.shape}\")\n",
    "print(\"The weights will have a shape of ([3, 2])\")\n",
    "print(\"The outputs key, value, query vectors shape will be ([6, 3])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ebe9f3-5e9d-4850-8e8a-b511a21fc0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the shape of the weight matrices\n",
    "\n",
    "dimension_in = inputs.shape[-1] \n",
    "dimension_out = 2\n",
    "dimension_in, dimension_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45173bda-4fb6-4042-8f93-50252eede3fb",
   "metadata": {},
   "source": [
    "- **Note1:** In GPT-Like models the input and output dimensions are usually same\n",
    "- But for me i want to test the transformation between different dimensional spaces\n",
    "- **Note2:** We are setting the requires gradients to False because we are not plannning on optimizing the values\n",
    "- Backpropagation, my friend it is you who might seeing this repo am telling me i already know, is when we calculate the loss and modify the values so that the values converge to zero (minimize loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed3ce018-1c2a-4ccf-99de-465e266045a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]),\n",
       " Parameter containing:\n",
       " tensor([[0.8823, 0.9150],\n",
       "         [0.3829, 0.9593],\n",
       "         [0.3904, 0.6009]]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the random weights matrices\n",
    "\n",
    "# Setting the random seed\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "# Initialization\n",
    "w_query = torch.nn.Parameter(torch.rand(dimension_in, dimension_out), requires_grad=False)\n",
    "w_key = torch.nn.Parameter(torch.rand(dimension_in, dimension_out), requires_grad=False)\n",
    "w_value = torch.nn.Parameter(torch.rand(dimension_in, dimension_out), requires_grad=False)\n",
    "# Checking an example and its shape -  must be viable for matrix mulitiplication with the inputs\n",
    "w_query.shape, w_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fc937-d91e-4fe9-918d-d77b3b42b50f",
   "metadata": {},
   "source": [
    "## Calculating Key, Query and Value matrices - matrix multiplication\n",
    "\n",
    "matrice = inputs * weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f19d8284-a06c-4e94-b78c-4022f5232be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the key, query vector for an individual token\n",
    "\n",
    "token = inputs[0]\n",
    "\n",
    "query_v_token = token @ w_query\n",
    "key_v_token = token @ w_key\n",
    "value_v_token = token @ w_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bd59d8-1686-402e-8744-0a37eae2212d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.7843, 1.0721],\n",
       "         [1.0760, 1.7344],\n",
       "         [1.0782, 1.7215],\n",
       "         [0.5450, 0.9560],\n",
       "         [0.8141, 1.0045],\n",
       "         [0.5652, 1.1437]]),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performing the matrix multiplications\n",
    "query_matrix = inputs @ w_query\n",
    "key_matrix = inputs @ w_key\n",
    "value_matrix = inputs @ w_value\n",
    "# Checking the results using one example\n",
    "query_matrix, query_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e43bdaf-da58-422d-b642-db1907907cc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2731, 0.8193],\n",
       "        [1.7073, 1.0646],\n",
       "        [1.6922, 1.0559],\n",
       "        [0.9133, 0.5633],\n",
       "        [0.9433, 0.6019],\n",
       "        [1.1233, 0.6876]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cbd4f40-424e-4036-a31a-0429162daa88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing if the complete and individual coincide\n",
    "\n",
    "query_v_token == query_matrix[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c94f1f1-bbcb-48d7-9413-1145c25e2e75",
   "metadata": {},
   "source": [
    "## Obtaining attention score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3807ed8-29b8-49f1-ab0a-4fddf715770a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7843, 1.0721],\n",
       "        [1.0760, 1.7344],\n",
       "        [1.0782, 1.7215],\n",
       "        [0.5450, 0.9560],\n",
       "        [0.8141, 1.0045],\n",
       "        [0.5652, 1.1437]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let each row represent the query vector for a token\n",
    "\n",
    "query_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ad527e7-a50a-4cba-aad5-fc7117fe47cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0832, 0.8895],\n",
       "         [1.5764, 0.9441],\n",
       "         [1.5440, 0.9455],\n",
       "         [0.9105, 0.4477],\n",
       "         [0.5262, 0.7038],\n",
       "         [1.2795, 0.4727]]),\n",
       " torch.Size([6, 2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let each row represent the key vector for each token\n",
    "\n",
    "key_matrix, key_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee51b9b1-7693-4289-b099-330dfb9fce2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([2, 6]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_matrix[1].shape, key_matrix.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69d33604-d35a-453e-9d78-43c9823e7cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.7084, 3.3338, 3.3013, 1.7563, 1.7869, 2.1966])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets get the attention score for the second query\n",
    "token = query_matrix[1]\n",
    "attention_score_query2 = token @ key_matrix.T\n",
    "attention_score_query2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e324670-e86a-4724-8d75-b43b0f200398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the above tensor means\n",
    "#2.7084 - how much the first token attends to the second token(query)\n",
    "#3.3338 - how much the second token attends to the query\n",
    "#and so on so forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f126f222-8589-4dea-b5f3-8f9c8b640039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8033, 2.2486, 2.2247, 1.1941, 1.1672, 1.5103],\n",
       "        [2.7084, 3.3338, 3.3013, 1.7563, 1.7869, 2.1966],\n",
       "        [2.6993, 3.3251, 3.2925, 1.7525, 1.7789, 2.1933],\n",
       "        [1.4408, 1.7618, 1.7454, 0.9243, 0.9596, 1.1492],\n",
       "        [1.7754, 2.2317, 2.2067, 1.1910, 1.1353, 1.5164],\n",
       "        [1.6295, 1.9707, 1.9539, 1.0266, 1.1023, 1.2637]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets get the attention scores for all the queries\n",
    "\n",
    "all_attention_scores = query_matrix @ key_matrix.T\n",
    "all_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02ab94c8-ace7-4948-85c7-c25f00cec39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each row shows how the other keys relate to the query just like the one token attention score but now for all tokens not just the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bcce7ea-acfb-4fd5-9cea-04323c0296a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the similar to the above formula just longer\n",
    "\n",
    "b = torch.empty([6, 6])\n",
    "for i, x_i in enumerate(query_matrix):\n",
    "    for j, x_j in enumerate(key_matrix):\n",
    "        b[i, j] = torch.dot(x_i, x_j)\n",
    "b == all_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8879b-cda1-466a-b5ce-a7d67839f79b",
   "metadata": {},
   "source": [
    "## Scaled dot product attention\n",
    "\n",
    "We scale the attention scores by dividing them by the squareroot of the embedding dimension of the keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115f7f99-821e-4dfc-a772-dc072ecf1e86",
   "metadata": {},
   "source": [
    "## Reasons for scaling\n",
    "\n",
    "1. Stability in learning - softmax is sensitive to the maginitude of the inputs in that when the inputs are large the difference btwn the exponential values of each input becomes much more pronounce and the highest values receives almost all the probability mass\n",
    "2. Reduce the values - if the dot product between the query and keys becomes to large it results in a sharp softmax distribution making the model overly confident in one particular key this can make learning unstable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f3ed391-1be3-4421-bfd3-a61d0171ac76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872]),\n",
       " tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stability learning example\n",
    "\n",
    "x = torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])\n",
    "a = torch.softmax(x, dim=-1)\n",
    "y = x * 8\n",
    "b = torch.softmax(y, dim=-1)\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a1506d-26ec-4d13-ae1c-8cc1021b8389",
   "metadata": {},
   "source": [
    "## But why squareroot(dimension)\n",
    "\n",
    "This is to make the variance of the dot product stable\n",
    "\n",
    "The variance of the dot product of query and key increases because multiplying two random numbers increases variance\n",
    "\n",
    "The variance increases with dimension \n",
    "\n",
    "Dividing the product / sqrt(dimension) keeps the variance close to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "222d96fb-ab2e-4fa0-afec-562455054830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions = 5 \t: variance after = 0.0457792164085009 variance before = 0.22889608204250453\n",
      "Dimensions = 20 : variance after = 0.05038295061271449 variance before = 1.0076590122542899\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def getVariance(dim, num_trials=1000):\n",
    "    dot_products = []\n",
    "    scaled_dot_products = []\n",
    "    for _ in range(num_trials):\n",
    "        q = np.random.rand(dim)\n",
    "        k = np.random.rand(dim)\n",
    "        dot_product = np.dot(q, k)\n",
    "        scaled_dot_product = dot_product / np.sqrt(dim)\n",
    "        dot_products.append(dot_product)\n",
    "        scaled_dot_products.append(scaled_dot_product)\n",
    "    scaled_var = np.var(scaled_dot_products)\n",
    "    unscaled_var = np.var(dot_products)\n",
    "    return scaled_var, unscaled_var\n",
    "\n",
    "variance_scaled_5, variance_unscaled_5 = getVariance(5)\n",
    "variance_scaled_20, variance_unscaled_20 = getVariance(20)\n",
    "print(f\"Dimensions = 5 \\t: variance after = {variance_scaled_5} variance before = {variance_unscaled_5}\")\n",
    "print(f\"Dimensions = 20 : variance after = {variance_scaled_20} variance before = {variance_unscaled_20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "057ffc85-13d1-4432-b8ed-92cea2f9cf5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the dimension of the keys\n",
    "\n",
    "d_k = key_matrix.shape[-1]\n",
    "d_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d40fc24-8a58-403c-82ab-cb2907dc3def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2751, 1.5900, 1.5731, 0.8444, 0.8254, 1.0679],\n",
       "        [1.9152, 2.3574, 2.3344, 1.2419, 1.2635, 1.5533],\n",
       "        [1.9087, 2.3512, 2.3281, 1.2392, 1.2579, 1.5509],\n",
       "        [1.0188, 1.2457, 1.2342, 0.6536, 0.6785, 0.8126],\n",
       "        [1.2554, 1.5781, 1.5604, 0.8422, 0.8028, 1.0723],\n",
       "        [1.1523, 1.3935, 1.3816, 0.7259, 0.7794, 0.8936]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the attention scores\n",
    "\n",
    "scaled_attention_scores = all_attention_scores / d_k**0.5\n",
    "scaled_attention_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78012fd-ef70-4356-aeb7-3cfc676b0933",
   "metadata": {},
   "source": [
    "## Attention Weights - Normalizing all attention scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d30d1b0f-35d4-4cf1-9381-9e9fe418187f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 6])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6e9d2a81-1a3e-4d49-9646-bd43d572de35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1719, 0.2355, 0.2315, 0.1117, 0.1096, 0.1397],\n",
       "        [0.1723, 0.2681, 0.2620, 0.0879, 0.0898, 0.1200],\n",
       "        [0.1721, 0.2679, 0.2618, 0.0881, 0.0898, 0.1203],\n",
       "        [0.1750, 0.2196, 0.2171, 0.1215, 0.1245, 0.1424],\n",
       "        [0.1704, 0.2353, 0.2312, 0.1127, 0.1084, 0.1419],\n",
       "        [0.1772, 0.2255, 0.2228, 0.1157, 0.1220, 0.1368]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_weights = torch.softmax(scaled_attention_scores, dim=-1)\n",
    "attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4b18b01-c931-4e63-b8da-4106b5f7aed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing using the first row\n",
    "b = 0\n",
    "for i in attention_weights:\n",
    "    for j in i:\n",
    "        b += j\n",
    "    break    \n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c65787b-e947-44e9-833b-6e456b45cfcf",
   "metadata": {},
   "source": [
    "## Computing the Context Vector\n",
    "\n",
    "We compute it as a weighted sum over the value vectors\n",
    "\n",
    "context vector = attention weights matrix * values matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7e477e1-52ce-476e-a391-4aeb89a26b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3751, 0.8610],\n",
       "        [1.4201, 0.8892],\n",
       "        [1.4198, 0.8890],\n",
       "        [1.3533, 0.8476],\n",
       "        [1.3746, 0.8606],\n",
       "        [1.3620, 0.8532]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing the full context vector matrix\n",
    "\n",
    "all_context_vector = attention_weights @ value_matrix\n",
    "all_context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5faf3a4b-5832-4d63-b57a-1bf55033d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets compute for the second input token only\n",
    "\n",
    "token_attention_weight = attention_weights[1]\n",
    "context_vec_2 = token_attention_weight @ value_matrix\n",
    "context_vec_2 == all_context_vector[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636fc3c0-e6ea-4fbf-9813-f43bae1be7ad",
   "metadata": {},
   "source": [
    "## Compacting Self attention mechanism into a Pytorch class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0717c819-8896-4217-a297-87ea4f8a2c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3751, 0.8610],\n",
       "        [1.4201, 0.8892],\n",
       "        [1.4198, 0.8890],\n",
       "        [1.3533, 0.8476],\n",
       "        [1.3746, 0.8606],\n",
       "        [1.3620, 0.8532]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Defining the class\n",
    "class SelfAttentionV1(nn.Module):\n",
    "    # Creating the initializer\n",
    "    def __init__(self, d_in, d_out):\n",
    "        # Inheritance\n",
    "        super().__init__()\n",
    "        # Initializer the 3 key weight matrices\n",
    "        self.w_query = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.w_key = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.w_value = torch.nn.Parameter(torch.rand(d_in, d_out))\n",
    "    # A forward pass for the inputs\n",
    "    def forward(self, x):\n",
    "        # Computing the query key and values\n",
    "        keys = x @ self.w_key \n",
    "        values = x @ self.w_value\n",
    "        queries = x @ self.w_query\n",
    "        # Computing the attention scores\n",
    "        attn_score = queries @ keys.T\n",
    "        # Computing the attention weights\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_score / keys.shape[-1]**0.5,\n",
    "            dim = -1\n",
    "        )\n",
    "        # Computing the context vector\n",
    "        context_vec = attention_weights @ values\n",
    "        # Returning the context vector\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Initialization\n",
    "self_v1 = SelfAttentionV1(d_in=3, d_out=2)\n",
    "context_vectors = self_v1(inputs)\n",
    "context_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b22ff1-5809-447b-ae26-1c2225bd68f4",
   "metadata": {},
   "source": [
    "## Linear layers improvement\n",
    "\n",
    "- We can improve further the self attention version 1 by replacing nn.Parameter with nn.Linear which effectively perform matrix multiplication when the bias units are disabled\n",
    "\n",
    "- Additionally, a significant advantage of use of nn.Linear instead of nn.Parameter(torch.rand()..) is that it produces optimized weights enhancing more stable learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ec0f0161-e1ce-43ea-b86b-b9330e2163e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3751, 0.8610],\n",
       "        [1.4201, 0.8892],\n",
       "        [1.4198, 0.8890],\n",
       "        [1.3533, 0.8476],\n",
       "        [1.3746, 0.8606],\n",
       "        [1.3620, 0.8532]], grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "# Defining the class\n",
    "class SelfAttentionV2(nn.Module):\n",
    "    # Creating the initializer\n",
    "    def __init__(self, d_in, d_out, bias_units=False):\n",
    "        # Inheritance\n",
    "        super().__init__()\n",
    "        # Initializer the 3 key weight matrices\n",
    "        self.w_query = torch.nn.Linear(d_in, d_out, bias=bias_units)\n",
    "        self.w_key = torch.nn.Linear(d_in, d_out, bias=bias_units)\n",
    "        self.w_value = torch.nn.Linear(d_in, d_out, bias=bias_units)\n",
    "    # A forward pass for the inputs\n",
    "    def forward(self, x):\n",
    "        # Computing the query key and values\n",
    "        keys = x @ self.w_key \n",
    "        values = x @ self.w_value\n",
    "        queries = x @ self.w_query\n",
    "        # Computing the attention scores\n",
    "        attn_score = queries @ keys.T\n",
    "        # Computing the attention weights\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_score / keys.shape[-1]**0.5,\n",
    "            dim = -1\n",
    "        )\n",
    "        # Computing the context vector\n",
    "        context_vec = attn_weights @ values\n",
    "        # Returning the context vector\n",
    "        return context_vec\n",
    "\n",
    "torch.manual_seed(42)\n",
    "# Initialization\n",
    "self_v2 = SelfAttentionV2(d_in=3, d_out=2)\n",
    "context_vectors = self_v1(inputs)\n",
    "context_vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
